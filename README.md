# NYC-TAXI-DE-Project

# ğŸš€ Azure End-to-End Data Engineering Pipeline (From Zero to Pro)

ğŸ”— **GitHub Repository:** https://github.com/yourusername/azure-end-to-end-data-engineering

---

## ğŸ“š Table of Contents
1. [Project Overview](#project-overview)  
2. [ğŸ—ï¸ Architecture](#architecture)  
3. [ğŸ’¾ Data Sources](#data-sources)  
4. [âš™ï¸ Key Features & Concepts](#key-features--concepts)  
5. [ğŸ”§ Technology Stack](#technology-stack)  
6. [ğŸš€ Getting Started](#getting-started)  
   - ğŸ› ï¸ [Prerequisites](#prerequisites)  
   - ğŸ“¥ [Clone the Repo](#clone-the-repo)  
   - â˜ï¸ [Azure Provisioning](#azure-provisioning)  
   - âš™ï¸ [Configuration](#configuration)  
   - â–¶ï¸ [Deployment & Execution](#deployment--execution)  
7. [ğŸ“‚ Folder Structure](#folder-structure)  
8. [ğŸ§  Key Learnings & Challenges](#key-learnings--challenges)  
9. [ğŸ”® Future Improvements](#future-improvements)  
10. [ğŸ“– References](#references)  

---

## ğŸ“š Project Overview
A production-grade data pipeline on Microsoft Azure that:
- **Ingests** monthly NYC â€œGreen Taxiâ€ Parquet files directly from the NYC Open Data API.  
- **Processes** data through Bronze â†’ Silver â†’ Gold Delta Lake layers in Azure Databricks.  
- **Implements** dynamic orchestration with Azure Data Factory (ADF), SCD Type 2 history tracking, secure secrets via Key Vault, and parallel execution.  
- **Serves** curated fact & dimension tables to Power BI for interactive analytics.  

---

## ğŸ—ï¸ Architecture
```text
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  NYC Open Data API â”‚      â”‚   Static Lookups    â”‚
            â”‚   (Green Taxi)     â”‚      â”‚  (zone_lookup.csv)  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚                           â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚                    Azure Data Factory (ADF)                â”‚
     â”‚  â€¢ Lookup JSON config â†’ ForEach(months)                    â”‚
     â”‚  â€¢ Copy Activities â†’ Bronze zone in ADLS Gen2              â”‚
     â”‚  â€¢ Trigger Databricks notebooks via Notebook Activity      â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚     Bronze Zone       â”‚
          â”‚ ADLS Gen2 (raw Parquetâ”‚
          â”‚    & lookup CSV)      â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚     Silver Zone       â”‚
          â”‚ Databricks Notebooks  â”‚
          â”‚ â€¢ Schema Conformance  â”‚
          â”‚ â€¢ SCD Type 2 Merges   â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚      Gold Zone        â”‚
          â”‚ Databricks Jobs       â”‚
          â”‚ â€¢ Fact & Dim Tables   â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚     Power BI Live     â”‚
          â”‚   Connector to Gold   â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ’¾ Data Sources
ğŸŸ¢ NYC Taxi â€œGreenâ€ API
Monthly Parquet files pulled via REST API.

ğŸ“‘ Zone Lookup CSV
Static reference mapping LocationID â†’ Borough, Zone Name.

âš™ï¸ Config JSON
Defines active months, file patterns, ADLS paths for dynamic ADF pipelines.

âš™ï¸ Key Features & Concepts
Dynamic, Parameterized ADF Pipelines

ADF Lookup reads config/green_taxi_config.json.

ForEach iterates over each month, injecting parameters into Copy & Notebook activities.

Medallion Architecture (Bronze â†’ Silver â†’ Gold)

Bronze: Raw Parquet + CSV in ADLS Gen2.

Silver: PySpark in Databricks for schema standardization, surrogate keys.

Gold: Star-schema FactTrips & Dimensions for analytics.

SCD Type 2 History Tracking

sql
Copy
Edit
MERGE INTO silver.Trips AS tgt
USING updates AS src
  ON tgt.trip_id = src.trip_id AND tgt.is_current = true
WHEN MATCHED AND src.* <> tgt.* THEN
  UPDATE SET is_current = false, end_date = current_timestamp()
WHEN NOT MATCHED THEN
  INSERT *
Preserves change history with start_date, end_date, is_current.

Delta Lake Best Practices

Partition by month, payment_type.

Z-ORDER on high-cardinality columns.

Time Travel for point-in-time queries & recovery.

Secure Secret Management

Azure Key Vault stores storage & Databricks credentials.

ADF & Databricks access secrets via Managed Identitiesâ€”no hard-coded keys.

Parallel Execution & Audit

ForEach batchCount = 6 for concurrent month processing.

Audit table in Azure SQL tracks pipeline run status & row counts.

Power BI Connectivity

Live connector to Gold Delta tables for sub-hourly dashboard refreshes.

ğŸ”§ Technology Stack
Layer	Tools & Services
Orchestration	Azure Data Factory
Storage	Azure Data Lake Storage Gen2
Compute	Azure Databricks (PySpark, Delta Lake)
Security	Azure Key Vault, Managed Identities
Visualization	Power BI
Source Control	Git & GitHub
API	NYC Open Data REST API

ğŸš€ Getting Started
ğŸ› ï¸ Prerequisites
Azure subscription with:

Data Factory, Storage Account (ADLS Gen2), Databricks workspace, Key Vault

Local tools: Azure CLI, Databricks CLI, Git

ğŸ“¥ Clone the Repo
bash
Copy
Edit
git clone https://github.com/yourusername/azure-end-to-end-data-engineering.git
cd azure-end-to-end-data-engineering
â˜ï¸ Azure Provisioning
bash
Copy
Edit
# Create resource group
az group create --name rg-data-pipeline --location eastus

# Storage account & containers
az storage account create --name dldevelstorage --resource-group rg-data-pipeline --hierarchical-namespace true
az storage container create --name bronze --account-name dldevelstorage
az storage container create --name lookup --account-name dldevelstorage
az storage container create --name silver --account-name dldevelstorage
az storage container create --name gold --account-name dldevelstorage

# Key Vault & secrets
az keyvault create --name kv-data-pipeline --resource-group rg-data-pipeline
az keyvault secret set --vault-name kv-data-pipeline --name "StorageKey" --value "<storage-key>"
az keyvault secret set --vault-name kv-data-pipeline --name "DatabricksPAT" --value "<databricks-pat>"
âš™ï¸ Configuration
Upload zone_lookup.csv to lookup/ container.

Place config/green_taxi_config.json in lookup/ on ADLS:

json
Copy
Edit
[
  { "month": "202201", "isActive": true },
  { "month": "202202", "isActive": true },
  â€¦  
  { "month": "202212", "isActive": false }
]
â–¶ï¸ Deployment & Execution
Import ADF Pipelines from pipelines/ADF_JSON_definitions/ into your Data Factory.

Configure ADF Linked Services to reference Key Vault secrets.

Trigger pipeline_green_taxi_master in ADF.

Monitor runs in ADF Monitor & view audit table in Azure SQL.

Validate Delta tables in Databricks:

sql
Copy
Edit
SELECT COUNT(*) FROM gold.factTrips;
DESCRIBE HISTORY silver.Trips;
Connect Power BI to Gold schema via Databricks connector.

ğŸ“‚ Folder Structure
pgsql
Copy
Edit
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ green_taxi_config.json
â”œâ”€â”€ lookup/
â”‚   â””â”€â”€ zone_lookup.csv
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_ingest_bronze.py
â”‚   â”œâ”€â”€ 02_transform_silver.py
â”‚   â””â”€â”€ 03_build_gold.py
â”œâ”€â”€ pipelines/
â”‚   â””â”€â”€ ADF_JSON_definitions/
â””â”€â”€ README.md
ğŸ§  Key Learnings & Challenges
Dynamic Orchestration: JSON-driven pipelines eliminated manual edits for new months.

SCD Type 2 Merges: Mastered Delta Lake MERGE syntax for history tracking.

Parallelization Pitfalls: Removed sequential bottlenecks in ForEach & audit table auto-increment.

Security Best Practices: Centralized secrets in Key Vault; used Managed Identities.

ğŸ”® Future Improvements
âš¡ Integrate CDC streams via Event Hubs for near real-time ingest.

ğŸ“Š Adopt Unity Catalog in Databricks for unified governance & lineage.

ğŸ”„ Implement CI/CD for ADF & notebooks via Azure DevOps or GitHub Actions.

âœ… Add automated data quality checks with Deequ or Great Expectations.

ğŸ“– References
Azure Data Factory Documentation

Delta Lake Guide

Azure Databricks Best Practices

NYC Open Data API

makefile
Copy
Edit
::contentReference[oaicite:0]{index=0}
